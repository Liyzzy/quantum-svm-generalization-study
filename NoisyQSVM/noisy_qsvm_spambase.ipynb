{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2008d1",
   "metadata": {},
   "source": [
    "##### Noisy QSVM - Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a2cc5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qiskit: 1.4.4\n",
      "Aer: 0.17.2\n",
      "QML: 0.8.4\n"
     ]
    }
   ],
   "source": [
    "import qiskit, qiskit_aer, qiskit_machine_learning\n",
    "print(\"Qiskit:\", qiskit.__version__)\n",
    "print(\"Aer:\", qiskit_aer.__version__)\n",
    "print(\"QML:\", qiskit_machine_learning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1276f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducibility of results\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18c932a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45c23a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qiskit and Qiskit Aer imports\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "# from qiskit.primitives import StatevectorSampler as Sampler\n",
    "from qiskit_aer.primitives import SamplerV2 as Sampler\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit_ibm_runtime.fake_provider import FakeBrisbane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58b0540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Spambase Column Names ---\n",
    "spambase_columns = [\n",
    "    \"word_freq_make\",\n",
    "    \"word_freq_address\",\n",
    "    \"word_freq_all\",\n",
    "    \"word_freq_3d\",\n",
    "    \"word_freq_our\",\n",
    "    \"word_freq_over\",\n",
    "    \"word_freq_remove\",\n",
    "    \"word_freq_internet\",\n",
    "    \"word_freq_order\",\n",
    "    \"word_freq_mail\",\n",
    "    \"word_freq_receive\",\n",
    "    \"word_freq_will\",\n",
    "    \"word_freq_people\",\n",
    "    \"word_freq_report\",\n",
    "    \"word_freq_addresses\",\n",
    "    \"word_freq_free\",\n",
    "    \"word_freq_business\",\n",
    "    \"word_freq_email\",\n",
    "    \"word_freq_you\",\n",
    "    \"word_freq_credit\",\n",
    "    \"word_freq_your\",\n",
    "    \"word_freq_font\",\n",
    "    \"word_freq_000\",\n",
    "    \"word_freq_money\",\n",
    "    \"word_freq_hp\",\n",
    "    \"word_freq_hpl\",\n",
    "    \"word_freq_george\",\n",
    "    \"word_freq_650\",\n",
    "    \"word_freq_lab\",\n",
    "    \"word_freq_labs\",\n",
    "    \"word_freq_telnet\",\n",
    "    \"word_freq_857\",\n",
    "    \"word_freq_data\",\n",
    "    \"word_freq_415\",\n",
    "    \"word_freq_85\",\n",
    "    \"word_freq_technology\",\n",
    "    \"word_freq_1999\",\n",
    "    \"word_freq_parts\",\n",
    "    \"word_freq_pm\",\n",
    "    \"word_freq_direct\",\n",
    "    \"word_freq_cs\",\n",
    "    \"word_freq_meeting\",\n",
    "    \"word_freq_original\",\n",
    "    \"word_freq_project\",\n",
    "    \"word_freq_re\",\n",
    "    \"word_freq_edu\",\n",
    "    \"word_freq_table\",\n",
    "    \"word_freq_conference\",\n",
    "    \"char_freq_;\",\n",
    "    \"char_freq_(\",\n",
    "    \"char_freq_[\",\n",
    "    \"char_freq_!\",\n",
    "    \"char_freq_$\",\n",
    "    \"char_freq_#\",\n",
    "    \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\",\n",
    "    # finally the target label column:\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# --- 1. Load the Spambase Dataset ---\n",
    "file_path = r'C:\\Users\\User\\Documents\\MyProjects\\FYP_ResearchProject\\data\\spambase\\spambase.data'\n",
    "df = pd.read_csv(file_path, header=None, names=spambase_columns)\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ad4233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Separate features and target\n",
    "X = df.drop('label', axis=1) # Columns axis 1, Rows axis 2 - just additional info\n",
    "y = df['label']\n",
    "\n",
    "# Now got : \n",
    "# Features - X\n",
    "# Target - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01bdcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# test_size - 0.3 means 30% as test set\n",
    "# random_state - ensures the random shuffling is the same every time the code runs\n",
    "# if its random, the result will be different and other people might ended up getting different results as well\n",
    "# stratify=y - nsures fairness when comparing classical SVM vs QSVM, especially if dataset is imbalanced (like more spam than non-spam emails).\n",
    "# Look at the labels in y, calculate the percentage of each class (like 80% Class A and 20% Class B), and make sure the new training set and \n",
    "# testing set both keep that exact same 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3883535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\\nPCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\\nPCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\\nAlso (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\\n\\nData leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\\n\\nAdditional Info:\\nWhy only scale and PCA the features x and not labels y\\n- X is because they are numerical\\n- So need better format of features (same range so they dont dominate), and reduce number of features to match the number of qubits\\n\\n- Y are class identifiers\\n- Not features \\n- If scaled they it destroys their meaning\\n\\nSummary :\\nScale + PCA → features (X)\\nDo not touch → labels (y)\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling and PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "'''\n",
    "StandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\n",
    "PCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\n",
    "PCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\n",
    "Also (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\n",
    "\n",
    "Data leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\n",
    "\n",
    "Additional Info:\n",
    "Why only scale and PCA the features x and not labels y\n",
    "- X is because they are numerical\n",
    "- So need better format of features (same range so they dont dominate), and reduce number of features to match the number of qubits\n",
    "\n",
    "- Y are class identifiers\n",
    "- Not features \n",
    "- If scaled they it destroys their meaning\n",
    "\n",
    "Summary :\n",
    "Scale + PCA → features (X)\n",
    "Do not touch → labels (y)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22dd3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a subset of 600 samples for training and testing.\n",
      "Training subset shape: (600, 4)\n",
      "\n",
      "Testing subset shape: (600, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a Medium-Sized Subset of Spambase Dataset for Faster Execution\n",
    "# Because took too long to run on full dataset\n",
    "subset_size = 600 \n",
    "X_train_subset = X_train_pca[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "\n",
    "# Same goes for test set\n",
    "X_test_subset = X_test_pca[:subset_size]\n",
    "y_test_subset = y_test[:subset_size]   \n",
    "\n",
    "# Check first\n",
    "print(f\"Using a subset of {subset_size} samples for training and testing.\")\n",
    "print(f\"Training subset shape: {X_train_subset.shape}\\n\")\n",
    "print(f\"Testing subset shape: {X_test_subset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86d275e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend_device = FakeManilaV2()\n",
    "\n",
    "# 2. Build the noise model from the backend's properties\n",
    "# noise_model = NoiseModel.from_backend(backend_device)\n",
    "\n",
    "# 3. Get other hardware-specific properties\n",
    "# coupling_map = backend_device.configuration().coupling_map\n",
    "# basis_gates = noise_model.basis_gates\n",
    "\n",
    "# 4. Create the AerSimulator configured with these properties\n",
    "# This simulator will now behave like the real FakeManilaV2 device\n",
    "# realistic_simulator = AerSimulator(\n",
    "#    noise_model=noise_model,\n",
    "#    coupling_map=coupling_map,\n",
    "#    basis_gates=basis_gates\n",
    "# )\n",
    "\n",
    "# print(\"Simulator configured successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99c0998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend = FakeKyoto()\n",
    "# noise_model = NoiseModel.from_backend(backend)\n",
    "# coupling_map = backend.configuration().coupling_map\n",
    "# basis_gates = noise_model.basis_gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2ae16",
   "metadata": {},
   "source": [
    "##### Quantum SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40e8d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the quantum feature map\n",
    "#fm = ZZFeatureMap(feature_dimension=n_components, reps=2, entanglement='linear')\n",
    "\n",
    "# print(\"\\n--- Creating high-performance noisy sampler ---\")\n",
    "# noisy_backend = AerSimulator(\n",
    "#     noise_model=noise_model,\n",
    "#     coupling_map=coupling_map,\n",
    "#     basis_gates=basis_gates,\n",
    "# )\n",
    "\n",
    "\n",
    "# print(\"Noisy backend created.\")\n",
    "# noisy_sampler = SamplerV2(mode=noisy_backend)\n",
    "# fidelity = ComputeUncompute(sampler=noisy_sampler)\n",
    "# noisy_qkernel = FidelityQuantumKernel(feature_map=fm, fidelity=fidelity)\n",
    "# print(\"Noisy quantum kernel created.\")\n",
    "\n",
    "# Perform a noise simulation\n",
    "# backend = AerSimulator(\n",
    "#    noise_model=noise_model,\n",
    "#    coupling_map=coupling_map,\n",
    "#    basis_gates=basis_gates\n",
    "#)\n",
    "\n",
    "# noisy_sampler = Sampler(mode=backend, options=None)\n",
    "# fidelity = ComputeUncompute(sampler=noisy_sampler)\n",
    "# noisy_qkernel = FidelityQuantumKernel(feature_map=fm, fidelity=fidelity)\n",
    "\n",
    "# print(\"Noisy quantum kernel created.\")\n",
    "\n",
    "# transpiled_circuit = transpile(fm, backend)\n",
    "# result = backend.run(transpiled_circuit).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "780b39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Configuring Realistic Backend Properties ---\n",
      "--- Noise model created from fake backend ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Configuring Realistic Backend Properties ---\")\n",
    "backend_device = FakeBrisbane()\n",
    "noisy_simulator = AerSimulator.from_backend(backend_device)\n",
    "print(\"--- Noise model created from fake backend ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4d923b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The sampler should be an instance of BaseSamplerV2, but got <class 'abc.ABCMeta'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Build feature map\u001b[39;00m\n\u001b[32m      6\u001b[39m fm = ZZFeatureMap(feature_dimension=n_components, reps=\u001b[32m2\u001b[39m, entanglement=\u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m fidelity = \u001b[43mComputeUncompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSampler\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# I think the problem is here\u001b[39;00m\n\u001b[32m      9\u001b[39m noisy_qkernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=fm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\qsvm_conda\\Lib\\site-packages\\qiskit_algorithms\\state_fidelities\\compute_uncompute.py:93\u001b[39m, in \u001b[36mComputeUncompute.__init__\u001b[39m\u001b[34m(self, sampler, shots, local, transpiler, transpiler_options)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    sampler: Sampler primitive instance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m \u001b[33;03m    ValueError: If the sampler is not an instance of ``BaseSamplerV2``.\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampler, BaseSamplerV2):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe sampler should be an instance of BaseSamplerV2, \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(sampler)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._sampler: BaseSamplerV2 = sampler\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m._local = local\n",
      "\u001b[31mValueError\u001b[39m: The sampler should be an instance of BaseSamplerV2, but got <class 'abc.ABCMeta'>"
     ]
    }
   ],
   "source": [
    "noisy_sampler = Sampler(\n",
    "    options={\"backend_options\": {\"noise_model\": backend_device, \"method\": \"density_matrix\"}}\n",
    ")\n",
    "\n",
    "# Build feature map\n",
    "fm = ZZFeatureMap(feature_dimension=n_components, reps=2, entanglement=\"linear\")\n",
    "\n",
    "fidelity = ComputeUncompute(sampler=Sampler) # I think the problem is here\n",
    "noisy_qkernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e94697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Computing Noisy Quantum Kernel Matrices (This may take a while) ---\n",
      "Calculating training kernel matrix...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'noisy_qkernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCalculating training kernel matrix...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m matrix_train_noisy = \u001b[43mnoisy_qkernel\u001b[49m.evaluate(x_vec=X_train_subset)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  -> Training matrix computed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCalculating testing kernel matrix...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'noisy_qkernel' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Compute the Noisy Kernel Matrices and Evaluate ---\n",
    "print(\"\\n--- Computing Noisy Quantum Kernel Matrices (This may take a while) ---\")\n",
    "# ... (The rest of the code is the same)\n",
    "print(\"Calculating training kernel matrix...\")\n",
    "start_time = time.time()\n",
    "matrix_train_noisy = noisy_qkernel.evaluate(x_vec=X_train_subset)\n",
    "print(f\"  -> Training matrix computed in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "print(\"Calculating testing kernel matrix...\")\n",
    "start_time = time.time()\n",
    "matrix_test_noisy = noisy_qkernel.evaluate(x_vec=X_test_subset, y_vec=X_train_subset)\n",
    "print(f\"  -> Testing matrix computed in {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf105bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed kernel precomputed to SVC\n",
    "qsvm_noisy = SVC(kernel='precomputed')\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "grid_search =  GridSearchCV(qsvm_noisy, param_grid, cv=5, verbose=0)\n",
    "grid_search.fit(matrix_train_noisy, y_train_subset)\n",
    "best_qsvm = grid_search.best_estimator_\n",
    "print(f\"Best C parameter found: {grid_search.best_params_['C']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32196988",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_qsvm.predict(matrix_test_noisy)\n",
    "test_accuracy = accuracy_score(y_test_subset, y_pred_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ce50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(\"\\n--- Noisy QSVM Results ---\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test_subset, y_test_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsvm_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50dece4",
   "metadata": {},
   "source": [
    "#### Ideal Quantum SVM - Spambase - Small Subset Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2517170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n",
      "Aer: 0.17.2\n"
     ]
    }
   ],
   "source": [
    "# Check Qiskit, Qiskit Aer versions, Qiskit Machine Learning - Versions\n",
    "import qiskit\n",
    "import qiskit_aer\n",
    "print(qiskit.__version__)\n",
    "print(\"Aer:\", qiskit_aer.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bf1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducibility of results\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff72cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Qiskit Imports\n",
    "# Definine quantum kernel\n",
    "# Use the FidelityQuantumKernel class \n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7263ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Spambase Column Names ---\n",
    "spambase_columns = [\n",
    "    \"word_freq_make\",\n",
    "    \"word_freq_address\",\n",
    "    \"word_freq_all\",\n",
    "    \"word_freq_3d\",\n",
    "    \"word_freq_our\",\n",
    "    \"word_freq_over\",\n",
    "    \"word_freq_remove\",\n",
    "    \"word_freq_internet\",\n",
    "    \"word_freq_order\",\n",
    "    \"word_freq_mail\",\n",
    "    \"word_freq_receive\",\n",
    "    \"word_freq_will\",\n",
    "    \"word_freq_people\",\n",
    "    \"word_freq_report\",\n",
    "    \"word_freq_addresses\",\n",
    "    \"word_freq_free\",\n",
    "    \"word_freq_business\",\n",
    "    \"word_freq_email\",\n",
    "    \"word_freq_you\",\n",
    "    \"word_freq_credit\",\n",
    "    \"word_freq_your\",\n",
    "    \"word_freq_font\",\n",
    "    \"word_freq_000\",\n",
    "    \"word_freq_money\",\n",
    "    \"word_freq_hp\",\n",
    "    \"word_freq_hpl\",\n",
    "    \"word_freq_george\",\n",
    "    \"word_freq_650\",\n",
    "    \"word_freq_lab\",\n",
    "    \"word_freq_labs\",\n",
    "    \"word_freq_telnet\",\n",
    "    \"word_freq_857\",\n",
    "    \"word_freq_data\",\n",
    "    \"word_freq_415\",\n",
    "    \"word_freq_85\",\n",
    "    \"word_freq_technology\",\n",
    "    \"word_freq_1999\",\n",
    "    \"word_freq_parts\",\n",
    "    \"word_freq_pm\",\n",
    "    \"word_freq_direct\",\n",
    "    \"word_freq_cs\",\n",
    "    \"word_freq_meeting\",\n",
    "    \"word_freq_original\",\n",
    "    \"word_freq_project\",\n",
    "    \"word_freq_re\",\n",
    "    \"word_freq_edu\",\n",
    "    \"word_freq_table\",\n",
    "    \"word_freq_conference\",\n",
    "    \"char_freq_;\",\n",
    "    \"char_freq_(\",\n",
    "    \"char_freq_[\",\n",
    "    \"char_freq_!\",\n",
    "    \"char_freq_$\",\n",
    "    \"char_freq_#\",\n",
    "    \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\",\n",
    "    # finally the target label column:\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# --- 1. Load the Spambase Dataset ---\n",
    "file_path = r'C:\\Users\\User\\Documents\\MyProjects\\FYP_ResearchProject\\data\\spambase\\spambase.data'\n",
    "df = pd.read_csv(file_path, header=None, names=spambase_columns)\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc76d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Separate features and target\n",
    "X = df.drop('label', axis=1) # Columns axis 1, Rows axis 2 - just additional info\n",
    "y = df['label']\n",
    "\n",
    "# Now got : \n",
    "# Features - X\n",
    "# Target - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf44654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# test_size - 0.3 means 30% as test set\n",
    "# random_state - ensures the random shuffling is the same every time the code runs\n",
    "# if its random, the result will be different and other people might ended up getting different results as well\n",
    "# stratify=y - nsures fairness when comparing classical SVM vs QSVM, especially if dataset is imbalanced (like more spam than non-spam emails).\n",
    "# Look at the labels in y, calculate the percentage of each class (like 80% Class A and 20% Class B), and make sure the new training set and \n",
    "# testing set both keep that exact same 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a63955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\\nPCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\\nPCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\\nAlso (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\\n\\nData leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\\n\\nAdditional Info:\\nWhy only scale and PCA the features x and not labels y\\n- X is because they are numerical\\n- So need better format of features (same range so they dont dominate), and reduce number of features to match the number of qubits\\n\\n- Y are class identifiers\\n- Not features \\n- If scaled they it destroys their meaning\\n\\nSummary :\\nScale + PCA → features (X)\\nDo not touch → labels (y)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "\n",
    "'''\n",
    "StandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\n",
    "PCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\n",
    "PCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\n",
    "Also (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\n",
    "\n",
    "Data leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\n",
    "\n",
    "Additional Info:\n",
    "Why only scale and PCA the features x and not labels y\n",
    "- X is because they are numerical\n",
    "- So need better format of features (same range so they dont dominate), and reduce number of features to match the number of qubits\n",
    "\n",
    "- Y are class identifiers\n",
    "- Not features \n",
    "- If scaled they it destroys their meaning\n",
    "\n",
    "Summary :\n",
    "Scale + PCA → features (X)\n",
    "Do not touch → labels (y)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88c3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection (based on correlation)\n",
    "THRESH = 0.9\n",
    "corr_matrix_train = X_train_scaled_df.corr().abs()\n",
    "upper_triangle = corr_matrix_train.where(np.triu(np.ones(corr_matrix_train.shape), k=1).astype(bool))\n",
    "columns_to_drop = set()\n",
    "for column in upper_triangle.columns:\n",
    "    high_corr_partners = upper_triangle.index[upper_triangle[column] > THRESH].tolist()\n",
    "    if high_corr_partners:\n",
    "        for partner in high_corr_partners:\n",
    "            corr_main_vs_target = y_train.corr(X_train_scaled_df[column])\n",
    "            corr_partner_vs_target = y_train.corr(X_train_scaled_df[partner])\n",
    "            if abs(corr_main_vs_target) < abs(corr_partner_vs_target):\n",
    "                columns_to_drop.add(column)\n",
    "            else:\n",
    "                columns_to_drop.add(partner)\n",
    "\n",
    "to_drop_final = sorted(list(columns_to_drop))\n",
    "X_train_selected = X_train_scaled_df.drop(columns=to_drop_final)\n",
    "X_test_selected = X_test_scaled_df.drop(columns=to_drop_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3440d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Preprocessing Complete ---\n",
      "Final training data shape: (2947, 4)\n",
      "Final testing data shape: (1263, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_test_pca = pca.transform(X_test_selected)\n",
    "\n",
    "print(\"--- Data Preprocessing Complete ---\")\n",
    "print(f\"Final training data shape: {X_train_pca.shape}\")\n",
    "print(f\"Final testing data shape: {X_test_pca.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6095da",
   "metadata": {},
   "source": [
    "##### Quantum Kernel Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Kernel Setup - Ideal Setup\n",
    "fm = ZZFeatureMap(feature_dimension=n_components, reps=2, entanglement='linear')\n",
    "sampler = Sampler()\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "qkernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training kernel matrix...\n"
     ]
    }
   ],
   "source": [
    "# Compute Kernel Matrices\n",
    "print(\"Calculating training kernel matrix...\")\n",
    "start_time = time.time()\n",
    "matrix_train = qkernel.evaluate(x_vec=X_train_pca)\n",
    "end_time = time.time()\n",
    "print(f\"Training kernel matrix calculated in {end_time - start_time:.2f} seconds.\\n\")\n",
    "\n",
    "print(\"Calculating testing kernel matrix...\")\n",
    "start_time = time.time()\n",
    "matrix_test = qkernel.evaluate(x_vec=X_test_pca, y_vec=X_train_pca)\n",
    "end_time = time.time()\n",
    "print(f\"Testing kernel matrix calculated in {end_time - start_time:.2f} seconds.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde839a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training QSVM with Precomputed Kernel (Spambase Subset) ---\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Best parameters found: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Classification with SVC\n",
    "print(\"--- Training QSVM with Precomputed Kernel (Spambase) ---\")\n",
    "qsvm = SVC(kernel='precomputed', class_weight='balanced')\n",
    "\n",
    "# Grid Search for Hyperparameter C\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "grid_search = GridSearchCV(qsvm, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(matrix_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "best_qsvm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a0827",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed25fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ideal QSVM Evaluation (Spambase Subset of 600) ---\n",
      "Training Accuracy: 0.6100\n",
      "Test Accuracy:     0.5850\n",
      "Generalization Gap: 0.0250\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       351\n",
      "           1       0.00      0.00      0.00       249\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.29      0.50      0.37       600\n",
      "weighted avg       0.34      0.58      0.43       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# For train data\n",
    "y_train_pred = best_qsvm.predict(matrix_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "y_test_pred = best_qsvm.predict(matrix_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "generalization_gap = abs(train_accuracy - test_accuracy)\n",
    "\n",
    "print(f\"\\n--- Ideal QSVM Evaluation (Spambase) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Generalization Gap: {generalization_gap:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsvm_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1797cec",
   "metadata": {},
   "source": [
    "#### Classical SVM Implementation - Spambase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1fa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Import Spambase Column Names ---\n",
    "spambase_columns = [\n",
    "    \"word_freq_make\",\n",
    "    \"word_freq_address\",\n",
    "    \"word_freq_all\",\n",
    "    \"word_freq_3d\",\n",
    "    \"word_freq_our\",\n",
    "    \"word_freq_over\",\n",
    "    \"word_freq_remove\",\n",
    "    \"word_freq_internet\",\n",
    "    \"word_freq_order\",\n",
    "    \"word_freq_mail\",\n",
    "    \"word_freq_receive\",\n",
    "    \"word_freq_will\",\n",
    "    \"word_freq_people\",\n",
    "    \"word_freq_report\",\n",
    "    \"word_freq_addresses\",\n",
    "    \"word_freq_free\",\n",
    "    \"word_freq_business\",\n",
    "    \"word_freq_email\",\n",
    "    \"word_freq_you\",\n",
    "    \"word_freq_credit\",\n",
    "    \"word_freq_your\",\n",
    "    \"word_freq_font\",\n",
    "    \"word_freq_000\",\n",
    "    \"word_freq_money\",\n",
    "    \"word_freq_hp\",\n",
    "    \"word_freq_hpl\",\n",
    "    \"word_freq_george\",\n",
    "    \"word_freq_650\",\n",
    "    \"word_freq_lab\",\n",
    "    \"word_freq_labs\",\n",
    "    \"word_freq_telnet\",\n",
    "    \"word_freq_857\",\n",
    "    \"word_freq_data\",\n",
    "    \"word_freq_415\",\n",
    "    \"word_freq_85\",\n",
    "    \"word_freq_technology\",\n",
    "    \"word_freq_1999\",\n",
    "    \"word_freq_parts\",\n",
    "    \"word_freq_pm\",\n",
    "    \"word_freq_direct\",\n",
    "    \"word_freq_cs\",\n",
    "    \"word_freq_meeting\",\n",
    "    \"word_freq_original\",\n",
    "    \"word_freq_project\",\n",
    "    \"word_freq_re\",\n",
    "    \"word_freq_edu\",\n",
    "    \"word_freq_table\",\n",
    "    \"word_freq_conference\",\n",
    "    \"char_freq_;\",\n",
    "    \"char_freq_(\",\n",
    "    \"char_freq_[\",\n",
    "    \"char_freq_!\",\n",
    "    \"char_freq_$\",\n",
    "    \"char_freq_#\",\n",
    "    \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\",\n",
    "    # finally the target label column:\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# Load data\n",
    "file_path = r'C:\\Users\\User\\Documents\\MyProjects\\FYP_ResearchProject\\data\\spambase\\spambase.data'\n",
    "df = pd.read_csv(file_path, header=None, names=spambase_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e2923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of Spambase data: (4601, 58)\n",
      "Shape after dropping duplicates: (4210, 58)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Some basic processing\n",
    "print(f\"Original shape of Spambase data: {df.shape}\") # Prints original dataset shape\n",
    "df.drop_duplicates(inplace=True) # Remove duplicates\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\\n\") # Then print again the new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae65f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7debf25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2947, 57)\n",
      "Testing set shape:  (1263, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n\\nUses the 70/30 split with stratify y\\nrandom state - reproducitbility\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Data Splitting\n",
    "# Using stratify=y to ensure that class distribution is same in train and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape:  {X_test.shape}\")\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Uses the 70/30 split with stratify y\n",
    "random state - reproducitbility\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07d158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\\nPCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\\nPCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\\nAlso (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\\n\\nData leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling and PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # use .transform not fit_transform\n",
    "\n",
    "# Convert back to DataFrames to retain column names for the next step\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "\"\"\"\n",
    "StandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\n",
    "PCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\n",
    "PCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\n",
    "Also (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\n",
    "\n",
    "Data leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fc1ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Selection ---\n",
      "Found pair: ('word_freq_415', 'word_freq_857') with correlation > 0.9\n",
      "-> Dropping 'word_freq_415' (weaker correlation with target)\n",
      "\n",
      "Total features to drop (1): ['word_freq_415']\n",
      "\n",
      "Original number of features: 57\n",
      "Number of features after selection: 56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Selection ---\n",
    "print(\"--- Feature Selection ---\")\n",
    "THRESH = 0.9\n",
    "\n",
    "# Calculate correlation matrix on the SCALED TRAINING data\n",
    "corr_matrix_train = X_train_scaled_df.corr().abs()\n",
    "\n",
    "# Get the upper triangle of the correlation matrix\n",
    "upper_triangle = corr_matrix_train.where(np.triu(np.ones(corr_matrix_train.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than the threshold\n",
    "columns_to_drop = set()\n",
    "for column in upper_triangle.columns:\n",
    "    high_corr_partners = upper_triangle.index[upper_triangle[column] > THRESH].tolist()\n",
    "    if high_corr_partners:\n",
    "        for partner in high_corr_partners:\n",
    "            # IMPORTANT: Check correlation with the TRAINING target variable\n",
    "            corr_main_vs_target = y_train.corr(X_train_scaled_df[column])\n",
    "            corr_partner_vs_target = y_train.corr(X_train_scaled_df[partner])\n",
    "            \n",
    "            print(f\"Found pair: ('{column}', '{partner}') with correlation > {THRESH}\")\n",
    "            if abs(corr_main_vs_target) < abs(corr_partner_vs_target):\n",
    "                columns_to_drop.add(column)\n",
    "                print(f\"-> Dropping '{column}' (weaker correlation with target)\")\n",
    "            else:\n",
    "                columns_to_drop.add(partner)\n",
    "                print(f\"-> Dropping '{partner}' (weaker correlation with target)\")\n",
    "\n",
    "to_drop_final = sorted(list(columns_to_drop))\n",
    "print(f\"\\nTotal features to drop ({len(to_drop_final)}): {to_drop_final}\")\n",
    "\n",
    "# Drop the identified columns from both training and test sets\n",
    "X_train_selected = X_train_scaled_df.drop(columns=to_drop_final)\n",
    "X_test_selected = X_test_scaled_df.drop(columns=to_drop_final)\n",
    "\n",
    "print(f\"\\nOriginal number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of features after selection: {X_train_selected.shape[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16ca5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after PCA (Train): (2947, 4)\n",
      "Shape after PCA (Test):  (1263, 4)\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "\n",
    "# Fit on the selected training data and transform both sets\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_test_pca = pca.transform(X_test_selected)\n",
    "\n",
    "print(f\"Shape after PCA (Train): {X_train_pca.shape}\")\n",
    "print(f\"Shape after PCA (Test):  {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e131a51",
   "metadata": {},
   "source": [
    "#### First Model - Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5da751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Classical Linear SVM ---\n",
      "Best parameters found: {'C': 1}\n",
      "Training time: 12.54 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDefines the grid of values for C (regularization strength).\\nUses GridSearchCV with 5-fold cross-validation → finds best C.\\nFits the Linear SVM.\\nFinds the best estimator.\\nRecords end time → training duration.\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First SVM Model - Classical Baseline (Linear SVM)\n",
    "\n",
    "print(\"--- Training Classical Linear SVM ---\")\n",
    "start_time_linear = time.time()\n",
    "\n",
    "param_grid_linear = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_linear = GridSearchCV(SVC(kernel='linear', random_state=42), param_grid_linear, cv=5, verbose=0)\n",
    "grid_linear.fit(X_train_pca, y_train)\n",
    "\n",
    "best_linear_svm = grid_linear.best_estimator_\n",
    "training_time_linear = time.time() - start_time_linear\n",
    "\n",
    "print(f\"Best parameters found: {grid_linear.best_params_}\")\n",
    "print(f\"Training time: {training_time_linear:.2f} seconds\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Defines the grid of values for C (regularization strength).\n",
    "Uses GridSearchCV with 5-fold cross-validation → finds best C.\n",
    "Fits the Linear SVM.\n",
    "Finds the best estimator.\n",
    "Records end time → training duration.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c0403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Linear SVM Evaluation (Spambase) ---\n",
      "Training Accuracy: 0.8748\n",
      "Test Accuracy:     0.8804\n",
      "Generalization Gap: 0.0057\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       759\n",
      "           1       0.89      0.80      0.84       504\n",
      "\n",
      "    accuracy                           0.88      1263\n",
      "   macro avg       0.88      0.87      0.87      1263\n",
      "weighted avg       0.88      0.88      0.88      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for Linear SVM\n",
    "\n",
    "# Predicts labels for both train and test sets\n",
    "# This is where the actual prediction works\n",
    "# linear_svm.predict - takes the features after all the scaling and PCA and output the predicted labels\n",
    "# X_train_pca → the training data features after preprocessing.\n",
    "# X_test_pca → the test data features after preprocessing.\n",
    "# y_train_pred_linear → model’s predicted labels for the training set.\n",
    "# y_test_pred_linear → model’s predicted labels for the test set.\n",
    "\n",
    "y_train_pred_linear = best_linear_svm.predict(X_train_pca)\n",
    "y_test_pred_linear = best_linear_svm.predict(X_test_pca)\n",
    "\n",
    "train_accuracy_linear = accuracy_score(y_train, y_train_pred_linear)\n",
    "test_accuracy_linear = accuracy_score(y_test, y_test_pred_linear)\n",
    "gen_gap_linear = abs(train_accuracy_linear - test_accuracy_linear)\n",
    "\n",
    "print(\"--- Linear SVM Evaluation (Spambase) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy_linear:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy_linear:.4f}\")\n",
    "print(f\"Generalization Gap: {gen_gap_linear:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3c1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcccba",
   "metadata": {},
   "source": [
    "#### Second Model - RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24476ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Classical RBF SVM ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training Classical RBF SVM ---\")\n",
    "start_time_rbf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "885c1449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Classical RBF SVM ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 10, 'gamma': 1}\n",
      "Training time: 37.63 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Training Classical RBF SVM ---\")\n",
    "start_time_rbf = time.time()\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "grid_rbf = GridSearchCV(SVC(kernel='rbf', random_state=42), param_grid_rbf, cv=5, verbose=0)\n",
    "grid_rbf.fit(X_train_pca, y_train)\n",
    "\n",
    "best_rbf_svm = grid_rbf.best_estimator_\n",
    "training_time_rbf = time.time() - start_time_rbf\n",
    "\n",
    "print(f\"Best parameters found: {grid_rbf.best_params_}\")\n",
    "print(f\"Training time: {training_time_rbf:.2f} seconds\\n\")\n",
    "\n",
    "\n",
    "# Defines parameter grid for C regularization and gamma (influence of each training point)\n",
    "# GridSearchCV finds best (C, gamma)\n",
    "# Fits RBF SVM\n",
    "# Then record the training time\n",
    "\n",
    "# C - controls the tradeoff between margin size and classification errors (Small C - big margin, Large C - Smaller margin) - Similar like the previous svm\n",
    "# Gamma - decides how far the influence of a single training point reaches (Small gamma - wide influence, decision boundary smoother, less flexible ,,,, Large Gamma - narrow influence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121b48f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RBF SVM Evaluation (Spambase) ---\n",
      "Training Accuracy: 0.9131\n",
      "Test Accuracy:     0.8884\n",
      "Generalization Gap: 0.0248\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       759\n",
      "           1       0.87      0.85      0.86       504\n",
      "\n",
      "    accuracy                           0.89      1263\n",
      "   macro avg       0.88      0.88      0.88      1263\n",
      "weighted avg       0.89      0.89      0.89      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for RBF SVM\n",
    "y_train_pred_rbf = best_rbf_svm.predict(X_train_pca)\n",
    "y_test_pred_rbf = best_rbf_svm.predict(X_test_pca)\n",
    "\n",
    "train_accuracy_rbf = accuracy_score(y_train, y_train_pred_rbf)\n",
    "test_accuracy_rbf = accuracy_score(y_test, y_test_pred_rbf)\n",
    "gen_gap_rbf = abs(train_accuracy_rbf - test_accuracy_rbf)\n",
    "\n",
    "print(\"--- RBF SVM Evaluation (Spambase) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy_rbf:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy_rbf:.4f}\")\n",
    "print(f\"Generalization Gap: {gen_gap_rbf:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_rbf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsvm_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

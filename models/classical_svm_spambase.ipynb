{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1797cec",
   "metadata": {},
   "source": [
    "#### Classical SVM Implementation - Spambase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1fa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Import Spambase Column Names ---\n",
    "spambase_columns = [\n",
    "    \"word_freq_make\",\n",
    "    \"word_freq_address\",\n",
    "    \"word_freq_all\",\n",
    "    \"word_freq_3d\",\n",
    "    \"word_freq_our\",\n",
    "    \"word_freq_over\",\n",
    "    \"word_freq_remove\",\n",
    "    \"word_freq_internet\",\n",
    "    \"word_freq_order\",\n",
    "    \"word_freq_mail\",\n",
    "    \"word_freq_receive\",\n",
    "    \"word_freq_will\",\n",
    "    \"word_freq_people\",\n",
    "    \"word_freq_report\",\n",
    "    \"word_freq_addresses\",\n",
    "    \"word_freq_free\",\n",
    "    \"word_freq_business\",\n",
    "    \"word_freq_email\",\n",
    "    \"word_freq_you\",\n",
    "    \"word_freq_credit\",\n",
    "    \"word_freq_your\",\n",
    "    \"word_freq_font\",\n",
    "    \"word_freq_000\",\n",
    "    \"word_freq_money\",\n",
    "    \"word_freq_hp\",\n",
    "    \"word_freq_hpl\",\n",
    "    \"word_freq_george\",\n",
    "    \"word_freq_650\",\n",
    "    \"word_freq_lab\",\n",
    "    \"word_freq_labs\",\n",
    "    \"word_freq_telnet\",\n",
    "    \"word_freq_857\",\n",
    "    \"word_freq_data\",\n",
    "    \"word_freq_415\",\n",
    "    \"word_freq_85\",\n",
    "    \"word_freq_technology\",\n",
    "    \"word_freq_1999\",\n",
    "    \"word_freq_parts\",\n",
    "    \"word_freq_pm\",\n",
    "    \"word_freq_direct\",\n",
    "    \"word_freq_cs\",\n",
    "    \"word_freq_meeting\",\n",
    "    \"word_freq_original\",\n",
    "    \"word_freq_project\",\n",
    "    \"word_freq_re\",\n",
    "    \"word_freq_edu\",\n",
    "    \"word_freq_table\",\n",
    "    \"word_freq_conference\",\n",
    "    \"char_freq_;\",\n",
    "    \"char_freq_(\",\n",
    "    \"char_freq_[\",\n",
    "    \"char_freq_!\",\n",
    "    \"char_freq_$\",\n",
    "    \"char_freq_#\",\n",
    "    \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\",\n",
    "    # finally the target label column:\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# Load data\n",
    "file_path = r'C:\\Users\\User\\Documents\\MyProjects\\FYP_ResearchProject\\data\\spambase\\spambase.data'\n",
    "df = pd.read_csv(file_path, header=None, names=spambase_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e2923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of Spambase data: (4601, 58)\n",
      "Shape after dropping duplicates: (4210, 58)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Some basic processing\n",
    "print(f\"Original shape of Spambase data: {df.shape}\") # Prints original dataset shape\n",
    "df.drop_duplicates(inplace=True) # Remove duplicates\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\\n\") # Then print again the new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7debf25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\nUses the 70/30 split with stratify y\\nrandom state - reproducitbility\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# 4. Data Splitting\n",
    "# Using stratify=y to ensure that class distribution is same in train and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "Uses the 70/30 split with stratify y\n",
    "random state - reproducitbility\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07d158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\\nPCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\\nPCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\\nAlso (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\\n\\nData leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling and PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # use .transform not fit_transform\n",
    "\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "StandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\n",
    "PCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\n",
    "PCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\n",
    "Also (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\n",
    "\n",
    "Data leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e131a51",
   "metadata": {},
   "source": [
    "#### First Model - Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5da751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Classical Linear SVM ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDefines a grid of values for C (regularization strength).\\nUses GridSearchCV with 5-fold cross-validation → finds best C.\\nFits the Linear SVM.\\nFinds the best estimator.\\nRecords end time → training duration.\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First SVM Model - Classical Baseline (Linear SVM)\n",
    "\n",
    "print(\"--- Training Classical Linear SVM ---\")\n",
    "start_time_linear = time.time() # To mark the start time for training\n",
    "\n",
    "# Grid C \n",
    "param_grid_linear = {'C' : [0.01, 0.1, 1, 10, 100]}\n",
    "grid_linear = GridSearchCV(SVC(kernel='linear', random_state=42), param_grid_linear, cv = 5, verbose = 0)\n",
    "grid_linear.fit(X_train_pca, y_train)\n",
    "linear_svm = grid_linear.best_estimator_\n",
    "end_time_linear = time.time()\n",
    "\n",
    "\"\"\"\n",
    "Defines the grid of values for C (regularization strength).\n",
    "Uses GridSearchCV with 5-fold cross-validation → finds best C.\n",
    "Fits the Linear SVM.\n",
    "Finds the best estimator.\n",
    "Records end time → training duration.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c0403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Linear SVM Evaluation (Spambase) ---\n",
      "Training Accuracy: 0.8744\n",
      "Test Accuracy:     0.8812\n",
      "Generalization Gap: 0.0068\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       759\n",
      "           1       0.89      0.81      0.84       504\n",
      "\n",
      "    accuracy                           0.88      1263\n",
      "   macro avg       0.88      0.87      0.87      1263\n",
      "weighted avg       0.88      0.88      0.88      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for Linear SVM\n",
    "\n",
    "# Predicts labels for both train and test sets\n",
    "# This is where the actual prediction works\n",
    "# linear_svm.predict - takes the features after all the scaling and PCA and output the predicted labels\n",
    "# X_train_pca → the training data features after preprocessing.\n",
    "# X_test_pca → the test data features after preprocessing.\n",
    "# y_train_pred_linear → model’s predicted labels for the training set.\n",
    "# y_test_pred_linear → model’s predicted labels for the test set.\n",
    "\n",
    "y_train_pred_linear = linear_svm.predict(X_train_pca)\n",
    "y_test_pred_linear = linear_svm.predict(X_test_pca)\n",
    "\n",
    "# Computes the accuracy for training and testing, also the generalization gap\n",
    "train_accuracy_linear = accuracy_score(y_train, y_train_pred_linear)\n",
    "test_accuracy_linear = accuracy_score(y_test, y_test_pred_linear)\n",
    "gen_gap_linear = abs(train_accuracy_linear - test_accuracy_linear)\n",
    "\n",
    "print(\"--- Linear SVM Evaluation (Spambase) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy_linear:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy_linear:.4f}\")\n",
    "print(f\"Generalization Gap: {gen_gap_linear:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_linear))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcccba",
   "metadata": {},
   "source": [
    "#### Second Model - RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24476ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Classical RBF SVM ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training Classical RBF SVM ---\")\n",
    "start_time_rbf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885c1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rbf = {\n",
    "    'C' : [0.1, 1, 10, 100],\n",
    "    'gamma' : [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_rbf = GridSearchCV(SVC(kernel='rbf', random_state=42), param_grid_rbf, cv=5, verbose=0)\n",
    "grid_rbf.fit(X_train_pca, y_train)\n",
    "rbf_svm = grid_rbf.best_estimator_\n",
    "end_time_rbf = time.time()\n",
    "\n",
    "# Defines parameter grid for C regularization and gamma (influence of each training point)\n",
    "# GridSearchCV finds best (C, gamma)\n",
    "# Fits RBF SVM\n",
    "# Then record the training time\n",
    "\n",
    "# C - controls the tradeoff between margin size and classification errors (Small C - big margin, Large C - Smaller margin) - Similar like the previous svm\n",
    "# Gamma - decides how far the influence of a single training point reaches (Small gamma - wide influence, decision boundary smoother, less flexible ,,,, Large Gamma - narrow influence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121b48f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RBF SVM Evaluation (Spambase) ---\n",
      "Training Accuracy: 0.9094\n",
      "Test Accuracy:     0.8915\n",
      "Generalization Gap: 0.0179\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       759\n",
      "           1       0.87      0.85      0.86       504\n",
      "\n",
      "    accuracy                           0.89      1263\n",
      "   macro avg       0.89      0.88      0.89      1263\n",
      "weighted avg       0.89      0.89      0.89      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for RBF SVM\n",
    "y_train_pred_rbf = rbf_svm.predict(X_train_pca)\n",
    "y_test_pred_rbf = rbf_svm.predict(X_test_pca)\n",
    "\n",
    "# Predict train/test labels\n",
    "train_accuracy_rbf = accuracy_score(y_train, y_train_pred_rbf)\n",
    "test_accuracy_rbf = accuracy_score(y_test, y_test_pred_rbf)\n",
    "gen_gap_rbf = abs(train_accuracy_rbf - test_accuracy_rbf)\n",
    "\n",
    "# Print out the precision, recall, F1-score.\n",
    "print(\"--- RBF SVM Evaluation (Spambase) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy_rbf:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy_rbf:.4f}\")\n",
    "print(f\"Generalization Gap: {gen_gap_rbf:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_rbf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsvm_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

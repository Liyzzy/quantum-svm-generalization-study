{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6792df01",
   "metadata": {},
   "source": [
    "##### Noisy Quantum SVM - Spambase - Small Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a614af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Qiskit, Qiskit Aer versions, Qiskit Machine Learning - Versions\n",
    "import qiskit\n",
    "import qiskit_aer\n",
    "print(qiskit.__version__)\n",
    "print(\"Aer:\", qiskit_aer.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducibility of results\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728be4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Qiskit Imports ---\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error, ReadoutError\n",
    "from qiskit_aer.primitives import SamplerV2 as AerSampler\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c38d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Spambase Column Names ---\n",
    "spambase_columns = [\n",
    "    \"word_freq_make\",\n",
    "    \"word_freq_address\",\n",
    "    \"word_freq_all\",\n",
    "    \"word_freq_3d\",\n",
    "    \"word_freq_our\",\n",
    "    \"word_freq_over\",\n",
    "    \"word_freq_remove\",\n",
    "    \"word_freq_internet\",\n",
    "    \"word_freq_order\",\n",
    "    \"word_freq_mail\",\n",
    "    \"word_freq_receive\",\n",
    "    \"word_freq_will\",\n",
    "    \"word_freq_people\",\n",
    "    \"word_freq_report\",\n",
    "    \"word_freq_addresses\",\n",
    "    \"word_freq_free\",\n",
    "    \"word_freq_business\",\n",
    "    \"word_freq_email\",\n",
    "    \"word_freq_you\",\n",
    "    \"word_freq_credit\",\n",
    "    \"word_freq_your\",\n",
    "    \"word_freq_font\",\n",
    "    \"word_freq_000\",\n",
    "    \"word_freq_money\",\n",
    "    \"word_freq_hp\",\n",
    "    \"word_freq_hpl\",\n",
    "    \"word_freq_george\",\n",
    "    \"word_freq_650\",\n",
    "    \"word_freq_lab\",\n",
    "    \"word_freq_labs\",\n",
    "    \"word_freq_telnet\",\n",
    "    \"word_freq_857\",\n",
    "    \"word_freq_data\",\n",
    "    \"word_freq_415\",\n",
    "    \"word_freq_85\",\n",
    "    \"word_freq_technology\",\n",
    "    \"word_freq_1999\",\n",
    "    \"word_freq_parts\",\n",
    "    \"word_freq_pm\",\n",
    "    \"word_freq_direct\",\n",
    "    \"word_freq_cs\",\n",
    "    \"word_freq_meeting\",\n",
    "    \"word_freq_original\",\n",
    "    \"word_freq_project\",\n",
    "    \"word_freq_re\",\n",
    "    \"word_freq_edu\",\n",
    "    \"word_freq_table\",\n",
    "    \"word_freq_conference\",\n",
    "    \"char_freq_;\",\n",
    "    \"char_freq_(\",\n",
    "    \"char_freq_[\",\n",
    "    \"char_freq_!\",\n",
    "    \"char_freq_$\",\n",
    "    \"char_freq_#\",\n",
    "    \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\",\n",
    "    # finally the target label column:\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# --- 1. Load the Spambase Dataset ---\n",
    "file_path = r'C:\\Users\\User\\Documents\\MyProjects\\FYP_ResearchProject\\data\\spambase\\spambase.data'\n",
    "df = pd.read_csv(file_path, header=None, names=spambase_columns)\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b486165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Some basic processing\n",
    "print(f\"Original shape of Spambase data: {df.shape}\") # Prints original dataset shape\n",
    "df.drop_duplicates(inplace=True) # Remove duplicates\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\\n\") # Then print again the new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cba238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Separate features and target\n",
    "X = df.drop('label', axis=1) # Columns axis 1, Rows axis 2 - just additional info\n",
    "y = df['label']\n",
    "\n",
    "# Now got : \n",
    "# Features - X\n",
    "# Target - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fraction = 0.2                     \n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X, y,\n",
    "    test_size=(1 - sample_fraction),\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Using stratified subsample of {len(X_sample)} instances \"\n",
    "      f\"({sample_fraction*100:.0f}% of original)\\n\")\n",
    "\n",
    "\n",
    "# Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sample, y_sample,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y_sample\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing  set shape: {X_test.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and PCA\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # use .transform not fit_transform\n",
    "\n",
    "# Convert back to DataFrames to retain column names for the next step\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Selection ---\n",
    "print(\"--- Feature Selection ---\")\n",
    "THRESH = 0.9\n",
    "\n",
    "# Calculate correlation matrix on the SCALED TRAINING data\n",
    "corr_matrix_train = X_train_scaled_df.corr().abs()\n",
    "\n",
    "# Get the upper triangle of the correlation matrix\n",
    "upper_triangle = corr_matrix_train.where(np.triu(np.ones(corr_matrix_train.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than the threshold\n",
    "columns_to_drop = set()\n",
    "for column in upper_triangle.columns:\n",
    "    high_corr_partners = upper_triangle.index[upper_triangle[column] > THRESH].tolist()\n",
    "    if high_corr_partners:\n",
    "        for partner in high_corr_partners:\n",
    "            # IMPORTANT: Check correlation with the TRAINING target variable\n",
    "            corr_main_vs_target = y_train.corr(X_train_scaled_df[column])\n",
    "            corr_partner_vs_target = y_train.corr(X_train_scaled_df[partner])\n",
    "            \n",
    "            print(f\"Found pair: ('{column}', '{partner}') with correlation > {THRESH}\")\n",
    "            if abs(corr_main_vs_target) < abs(corr_partner_vs_target):\n",
    "                columns_to_drop.add(column)\n",
    "                print(f\"-> Dropping '{column}' (weaker correlation with target)\")\n",
    "            else:\n",
    "                columns_to_drop.add(partner)\n",
    "                print(f\"-> Dropping '{partner}' (weaker correlation with target)\")\n",
    "\n",
    "to_drop_final = sorted(list(columns_to_drop))\n",
    "print(f\"\\nTotal features to drop ({len(to_drop_final)}): {to_drop_final}\")\n",
    "\n",
    "# Drop the identified columns from both training and test sets\n",
    "X_train_selected = X_train_scaled_df.drop(columns=to_drop_final)\n",
    "X_test_selected = X_test_scaled_df.drop(columns=to_drop_final)\n",
    "\n",
    "print(f\"\\nOriginal number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of features after selection: {X_train_selected.shape[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "\n",
    "# Fit on the selected training data and transform both sets\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_test_pca = pca.transform(X_test_selected)\n",
    "\n",
    "print(f\"Shape after PCA (Train): {X_train_pca.shape}\")\n",
    "print(f\"Shape after PCA (Test):  {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab52b0",
   "metadata": {},
   "source": [
    "##### Noise Simulation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b43366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Model implementation from (Depolarizing error and Readout Error)\n",
    "print(\"--- Setting up Noise Model ---\")\n",
    "# Error rates (realistic, not too high)\n",
    "p_gate_1q = 0.001   # 0.1% error for single-qubit gates (u1, u2, u3)\n",
    "p_gate_2q = 0.01    # 1.0% error for two-qubit gates (cx)\n",
    "p_readout = 0.02    # 2.0% chance of wrong measurement\n",
    "\n",
    "# Build the noise model\n",
    "noise_model = NoiseModel()\n",
    "\n",
    "noise_model.add_all_qubit_quantum_error(depolarizing_error(p_gate_1q, 1), ['u1', 'u2', 'u3'])\n",
    "noise_model.add_all_qubit_quantum_error(depolarizing_error(p_gate_2q, 2), ['cx'])\n",
    "\n",
    "# Add readout error (0 -> 1 or 1 -> 0)\n",
    "readout_error = ReadoutError([[1 - p_readout, p_readout], [p_readout, 1 - p_readout]])\n",
    "noise_model.add_all_qubit_readout_error(readout_error, ['measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f738278",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_backend = AerSimulator(\n",
    "    noise_model=noise_model,\n",
    "    seed_simulator=12345,\n",
    ")\n",
    "\n",
    "noise_sampler = AerSampler.from_backend(\n",
    "    backend=noisy_backend,\n",
    "    default_shots=8192,  # 8192 is good for QSVM; adjust if too slow\n",
    ")\n",
    "\n",
    "print(\"Noisy SamplerV2 ready for QSVM training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpilation pass manager\n",
    "pm = generate_preset_pass_manager(optimization_level=1, backend=noisy_backend)\n",
    "print (\"Realistic noise model applied !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259452e",
   "metadata": {},
   "source": [
    "##### Quantum Kernel Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb44613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature map setup\n",
    "feature_dim = n_components\n",
    "fm = ZZFeatureMap(feature_dimension=feature_dim, reps=2, entanglement='linear')\n",
    "\n",
    "# Fidelity with noisy sampler and transpilation\n",
    "fidelity = ComputeUncompute(sampler=noise_sampler, pass_manager=pm)\n",
    "\n",
    "# Noisy quantum kernel\n",
    "quantum_kernel_noisy = FidelityQuantumKernel(fidelity=fidelity, feature_map=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ideal kernel matrix (on a subset if large)\n",
    "matrix_train_noisy = quantum_kernel_noisy.evaluate(x_vec=X_train_pca[:50])  # Subset for plot if too large\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(matrix_train_noisy, cmap='viridis')\n",
    "plt.title(\"Noisy Kernel Matrix (Subset)\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideal QSVC with tuned parameters\n",
    "print(\"--- Training Ideal QSVC (Lung Cancer) ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    'C' : [0.1, 1, 10, 100],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Use cross-validation suitable for small/imbalanced data\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# qsvc_ideal = QSVC(quantum_kernel=qkernel, C=1, class_weight='balanced')\n",
    "# Grid search on QSVC\n",
    "grid_search = GridSearchCV(\n",
    "    QSVC(quantum_kernel=quantum_kernel_noisy),  # Your QSVC setup\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',  # Or 'f1_macro' for imbalanced classes\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # For progress output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f491c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca, y_train)\n",
    "qsvc_noisy = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "end_time = time.time()\n",
    "print(f\"QSVC training finished in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d6a68",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = qsvc_noisy.predict(X_train_pca)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "y_test_pred = qsvc_noisy.predict(X_test_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "generalization_gap = abs(train_accuracy - test_accuracy)\n",
    "\n",
    "print(f\"\\n--- Noisy QSVM Evaluation (Spambase) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Generalization Gap: {generalization_gap:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsvm_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

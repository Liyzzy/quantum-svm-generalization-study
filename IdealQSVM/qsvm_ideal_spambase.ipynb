{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50dece4",
   "metadata": {},
   "source": [
    "#### Ideal Quantum SVM - Spambase - Small Subset Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2517170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n",
      "Aer: 0.17.2\n"
     ]
    }
   ],
   "source": [
    "# Check Qiskit, Qiskit Aer versions, Qiskit Machine Learning - Versions\n",
    "import qiskit\n",
    "import qiskit_aer\n",
    "print(qiskit.__version__)\n",
    "print(\"Aer:\", qiskit_aer.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducibility of results\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff72cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Qiskit Imports\n",
    "# Definine quantum kernel\n",
    "# Use the FidelityQuantumKernel class \n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7263ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Spambase Column Names ---\n",
    "spambase_columns = [\n",
    "    \"word_freq_make\",\n",
    "    \"word_freq_address\",\n",
    "    \"word_freq_all\",\n",
    "    \"word_freq_3d\",\n",
    "    \"word_freq_our\",\n",
    "    \"word_freq_over\",\n",
    "    \"word_freq_remove\",\n",
    "    \"word_freq_internet\",\n",
    "    \"word_freq_order\",\n",
    "    \"word_freq_mail\",\n",
    "    \"word_freq_receive\",\n",
    "    \"word_freq_will\",\n",
    "    \"word_freq_people\",\n",
    "    \"word_freq_report\",\n",
    "    \"word_freq_addresses\",\n",
    "    \"word_freq_free\",\n",
    "    \"word_freq_business\",\n",
    "    \"word_freq_email\",\n",
    "    \"word_freq_you\",\n",
    "    \"word_freq_credit\",\n",
    "    \"word_freq_your\",\n",
    "    \"word_freq_font\",\n",
    "    \"word_freq_000\",\n",
    "    \"word_freq_money\",\n",
    "    \"word_freq_hp\",\n",
    "    \"word_freq_hpl\",\n",
    "    \"word_freq_george\",\n",
    "    \"word_freq_650\",\n",
    "    \"word_freq_lab\",\n",
    "    \"word_freq_labs\",\n",
    "    \"word_freq_telnet\",\n",
    "    \"word_freq_857\",\n",
    "    \"word_freq_data\",\n",
    "    \"word_freq_415\",\n",
    "    \"word_freq_85\",\n",
    "    \"word_freq_technology\",\n",
    "    \"word_freq_1999\",\n",
    "    \"word_freq_parts\",\n",
    "    \"word_freq_pm\",\n",
    "    \"word_freq_direct\",\n",
    "    \"word_freq_cs\",\n",
    "    \"word_freq_meeting\",\n",
    "    \"word_freq_original\",\n",
    "    \"word_freq_project\",\n",
    "    \"word_freq_re\",\n",
    "    \"word_freq_edu\",\n",
    "    \"word_freq_table\",\n",
    "    \"word_freq_conference\",\n",
    "    \"char_freq_;\",\n",
    "    \"char_freq_(\",\n",
    "    \"char_freq_[\",\n",
    "    \"char_freq_!\",\n",
    "    \"char_freq_$\",\n",
    "    \"char_freq_#\",\n",
    "    \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\",\n",
    "    # finally the target label column:\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# --- 1. Load the Spambase Dataset ---\n",
    "file_path = r'C:\\Users\\User\\Documents\\MyProjects\\FYP_ResearchProject\\data\\spambase\\spambase.data'\n",
    "df = pd.read_csv(file_path, header=None, names=spambase_columns)\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Separate features and target\n",
    "X = df.drop('label', axis=1) # Columns axis 1, Rows axis 2 - just additional info\n",
    "y = df['label']\n",
    "\n",
    "# Now got : \n",
    "# Features - X\n",
    "# Target - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf44654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# test_size - 0.3 means 30% as test set\n",
    "# random_state - ensures the random shuffling is the same every time the code runs\n",
    "# if its random, the result will be different and other people might ended up getting different results as well\n",
    "# stratify=y - nsures fairness when comparing classical SVM vs QSVM, especially if dataset is imbalanced (like more spam than non-spam emails).\n",
    "# Look at the labels in y, calculate the percentage of each class (like 80% Class A and 20% Class B), and make sure the new training set and \n",
    "# testing set both keep that exact same 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a63955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\\nPCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\\nPCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\\nAlso (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\\n\\nData leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\\n\\nAdditional Info:\\nWhy only scale and PCA the features x and not labels y\\n- X is because they are numerical\\n- So need better format of features (same range so they dont dominate), and reduce number of features to match the number of qubits\\n\\n- Y are class identifiers\\n- Not features \\n- If scaled they it destroys their meaning\\n\\nSummary :\\nScale + PCA → features (X)\\nDo not touch → labels (y)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling and PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "'''\n",
    "StandardScaler - as mentioned before, it normalizes the feature to mean 0, std 1\n",
    "PCA - reduces dimensionality to 4 principal components, 4 also because to match with the 4 qubit feature map\n",
    "PCA - also why choose change into 4 components is to match 4 qubits of ZZFeatureMap\n",
    "Also (Binary Classification) is just the classification between two classes. It does nothing to amount of qubits\n",
    "\n",
    "Data leakage - information from test sets sneaks into the training process, makes model look better because it looks like it seen some information\n",
    "\n",
    "Additional Info:\n",
    "Why only scale and PCA the features x and not labels y\n",
    "- X is because they are numerical\n",
    "- So need better format of features (same range so they dont dominate), and reduce number of features to match the number of qubits\n",
    "\n",
    "- Y are class identifiers\n",
    "- Not features \n",
    "- If scaled they it destroys their meaning\n",
    "\n",
    "Summary :\n",
    "Scale + PCA → features (X)\n",
    "Do not touch → labels (y)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73075f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a subset of 600 samples for training and testing.\n",
      "Training subset shape: (600, 4)\n",
      "\n",
      "Testing subset shape: (600, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a Medium-Sized Subset of Spambase Dataset for Faster Execution\n",
    "# Because took too long to run on full dataset\n",
    "subset_size = 600 \n",
    "X_train_subset = X_train_pca[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "\n",
    "# Same goes for test set\n",
    "X_test_subset = X_test_pca[:subset_size]\n",
    "y_test_subset = y_test[:subset_size]   \n",
    "\n",
    "# Check first\n",
    "print(f\"Using a subset of {subset_size} samples for training and testing.\")\n",
    "print(f\"Training subset shape: {X_train_subset.shape}\\n\")\n",
    "print(f\"Testing subset shape: {X_test_subset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6095da",
   "metadata": {},
   "source": [
    "##### Quantum Kernel Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Kernel Setup\n",
    "fm = ZZFeatureMap(feature_dimension=n_components, reps=2, entanglement='linear')\n",
    "sampler = Sampler()\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "qkernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training kernel matrix for the training subset...\n",
      "Training kernel matrix calculated in 2171.46 seconds.\n",
      "Calculating testing kernel matrix for the testing subset...\n",
      "Test kernel matrix calculated in 1743.46 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute those Kernel Matrices\n",
    "print(\"Calculating training kernel matrix for the training subset...\")\n",
    "start_time = time.time()\n",
    "matrix_train = qkernel.evaluate(x_vec = X_train_subset)\n",
    "end_time = time.time()\n",
    "print(f\"Training kernel matrix calculated in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# For test set\n",
    "print(\"Calculating testing kernel matrix for the testing subset...\")\n",
    "start_time = time.time()\n",
    "matrix_test = qkernel.evaluate(x_vec = X_test_subset, y_vec = X_train_subset)\n",
    "end_time = time.time()\n",
    "print(f\"Test kernel matrix calculated in {end_time - start_time:.2f} seconds.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde839a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training QSVM with Precomputed Kernel (Spambase Subset) ---\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Best parameters found: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Classification with SVC\n",
    "print(\"--- Training QSVM with Precomputed Kernel (Spambase Subset) ---\")\n",
    "qsvm = SVC(kernel='precomputed')\n",
    "\n",
    "# Grid Search for Hyperparameter C\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "grid_search = GridSearchCV(qsvm, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(matrix_train, y_train_subset)\n",
    "\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "best_qsvm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a0827",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed25fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ideal QSVM Evaluation (Spambase Subset of 600) ---\n",
      "Training Accuracy: 0.6100\n",
      "Test Accuracy:     0.5850\n",
      "Generalization Gap: 0.0250\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       351\n",
      "           1       0.00      0.00      0.00       249\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.29      0.50      0.37       600\n",
      "weighted avg       0.34      0.58      0.43       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# For train data\n",
    "y_train_pred = best_qsvm.predict(matrix_test)\n",
    "train_accuracy = accuracy_score(y_train_subset, y_train_pred)\n",
    "\n",
    "# For test data\n",
    "y_test_pred = best_qsvm.predict(matrix_test)\n",
    "test_accuracy = accuracy_score(y_test_subset, y_test_pred)\n",
    "\n",
    "# Calculate the generalization gap\n",
    "generalization_gap = abs(train_accuracy - test_accuracy)\n",
    "\n",
    "\n",
    "# Print all results \n",
    "print(f\"\\n--- Ideal QSVM Evaluation (Spambase Subset of {subset_size}) ---\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Generalization Gap: {generalization_gap:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test_subset, y_test_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsvm_env (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
